---
bibliography: citations.bib
---

# Thematic Analysis

## What?

- a method for identifying, analysing, and reporting patterns  (themes) within  data. [@Braun2006-lp]
- a qualitative research method that can be widely used across a range of epistemologies and research questions [@Nowell2017-qr]

### Abductive thematic analysis

- deductive
  - theory-driven
  - positivist methodologies
  - objectively test phenomena
- inductive
  - data-driven
  - exploratory approach
- abductive
  - a mix of both
  - pragmatism

[@Thompson2022-jk]

## Method

### 6 steps

1. Familiarize yourself with the data
2. Generate initial codes
3. Search for themes
4. Review themes
5. Define and name themes
6. Produce the report

[@Nowell2017-qr]

### 1. Familiarize yourself with the data

- Read and re-read the data
- Make notes of initial ideas
- Highlight interesting features
- Annotate the data with initial codes
- Write down initial thoughts
- Reflect on the data

### 2. Generate initial codes

- Start coding
- Code everything that seems interesting
- Code for as many themes as possible

### 3. Search for themes

- Look for patterns in the codes
- Look for connections between codes
- Look for connections between codes and the research question
- Look for connections between codes and the literature

### 4. Review themes

- Check if the themes work in relation to the coded extracts

### 5. Define and name themes

- Define what each theme is about
- Name each theme
- Write a description of each theme

### 6. Produce the report

- Write the report
- Use extracts from the data to illustrate the themes

by ChatGPT

### 8 steps for abductive thematic analysis

1. Transcription and Familiarisation
2. Coding
3. Codebook
4. Development of Themes
5. Theorising
6. Comparison of Datasets
7. Data Display
8. Writing Up

[@Thompson2022-jk]

### Using LLMs

#### Using ChatGPT review

| Reference | Country | GPT model | Use of ChatGPT or GPT | Findings | Challenges with ChatGPT or GPT |
|-|-|-|-|-|-|
| [@De-Paoli2024-ye] | United Kingdom | GPT-3.5 Turbo | The study used GPT to conduct thematic analysis, including generating initial codes, searching for themes, reviewing themes, and defining and naming themes. | GPT-3.5 Turbo was able to provide themes with synthetic descriptions. However, some inferred themes were not considered relevant by human researchers, and ChatGPT missed out on themes that were reported by human researchers. | Interviews had to be divided into chunks due to the token limit. Output is prompt-dependent (e.g., asking for a different number of themes produced a different set of themes). Hallucination (e.g., assigned incorrect code to theme). |
| [@De-Paoli2023-pi] | United Kingdom | GPT-3.5 Turbo | The study used GPT to build user personas (i.e., fictional yet realistic descriptions of a typical or target user of a product [20]) based on interview transcripts using thematic analysis. | GPT-3.5 Turbo was able to generate 2 relevant personas based on challenges and needs identified during thematic analysis. | Biased toward creating specific types of user personas (e.g., mostly middle-aged, from Italy). Required human intervention to refine codes and themes generated (e.g., generated code with a truncated quote). |
| [@Gao2023-ow] | Singapore and United States of America | GPT-3.5 | The study explored the functionality of CollabCoder (a data management prototype incorporating GPT-3.5) in assisting with open coding, iterative discussions, and the development of codebooks. | Participants valued GPT-3.5 for reducing cognitive burden during coding, but some participants cited that summaries generated by GPT-3.5 are too detailed and not relevant. | Does not consider research questions or the intended direction of analysis if not explicitly instructed. |
| [@Mesec2023-pn] | Slovenia | Information not available | The study used ChatGPT to conduct qualitative analysis using the grounded theory method. | ChatGPT was able to summarize and balance opposing ideas but tended to express ideas using descriptive terms at a lower level of abstraction compared to a human researcher. | Hallucination (e.g., made-up information in a summary of texts). Codes inadequately capture the content of the transcript. Unproductive repetition of output. Inappropriate use of terms (e.g., "we can form some qualitative analyses"). |
| [@Tabone2023-xg] | Netherlands | GPT-3.5 Turbo and GPT-4-0613 | The study used GPT to (1) conduct sentiment analysis, (2) provide meta-summaries of interviews, and (3) identify differences between 2 think-aloud transcripts. | Ratings (r=0.98) and summaries generated with GPT-3.5 were strongly correlated or generally in line with those generated by human researchers. GPT-3.5 was also able to summarize the descriptive differences between 2 transcripts. | Prompt-dependent (e.g., modified prompt increased correlation of ratings). Summary by GPT-4.0 was richer and touched on more facets than GPT-3.5 Turbo; however, some topics that were identified did not emerge in content analysis conducted by humans. |
| [@Taylor2024-am] | United States of America | Information not available | The study used ChatGPT to clean interview transcripts after using an artificial intelligence-assisted method to transcribe interviews. | ChatGPT cleaned redundant words and sentence fragments, but transcripts were more difficult to read due to ChatGPT connecting sentence fragments, which resulted in longer words per sentence. | Word and syntax errors remained in several transcriptions. Quality of transcription cleaning is dependent on the speech of the speaker (e.g., clarity, pauses, and filler words). Limited input word count (500-600 words as of March 2023). |
| [@Xiao2023-ls] | Canada and France | GPT-3 | The study used GPT to conduct deductive coding using an expert-developed codebook. | GPT-3 achieved fair to substantial agreement with human researchers (Cohen = 0.38-0.61). | The model occasionally produced incorrect labels. |

[@Lee2024-co]

