# Technology in Programmatic assessment

## Assessment and feedback lifecycle

Not focus on assessment tools, but see while system as lifecycle

![](Technology%20in%20Programmatic%20assessment/2022-10-23-16-57-23.png)

1. Specifying
    - the process of determining the details of a course or programme of study and consequently the assessment strategy within it
    - Technology
       - digital curriculum
           - e-syllabass
2. Setting
    - The purpose of setting is to achieve clarity for both students and staff: what is required, in what format, by when and how it will be assessed
    - Technology
       - online template
3. Supporting
    - Helping each student do their best work for each assignment. However the real purpose is developing students' assessment literacy so that they understand what is involved in the process of making academic judgements
    - Technology
        - formative feedback
          - online quizz or testing
          - electronic voting systems
4. Submitting
   - The process of students handing over their completed assignment to the appropriate person so that marking and/or feedback can take place
   - Technology
       - E-submission is rapidly becoming the norm
5. Marking and production of feedback
   - student work is formally evaluated against a set of predefined assessment criteria with marks and feedback provided
   - purpose
       - To give a piece of work a final grade in relation to the assessment criteria
       - To provide feedback to aid student longitudinal development.
   - Technology
       - e-marking and e-feedback 
6. Recording of grades
   - the culmination of marking and moderation processes  
   - give each summative assignment a definitive grade that describes how well the student has met the criteria for the assignment and hence the learning outcomes
   - Technology
       - marks recording systems
7. Returning marks and feedback
   - informs students about the outcomes of an assessed piece of work
   - Technology 
       - post marks and feedback direct to individual students without the need for manual intervention 
8. Reflecting
   - The aim of this stage is to ensure that students engage with their feedback and use it to improve their future performance
   - Technology
       - store feedback and make it accessible to students and staff
       - self-reflection on a portfolio of work and dialogue around feedback

https://www.jisc.ac.uk/guides/transforming-assessment-and-feedback/


Excellent framework for education in classrooms. Not fully fit to workplace-based learning.

## See as Data Flow

- Data gathering
    - learner
      - note or capture learning moment[@DOI:10.1007/s40037-016-0295-z]
    - teacher
    - curriculum developer[@DOI:10.1108/IJEM-10-2020-0494]
    - challenges
      - limited contact time
      - rotation
      - pressure of other duties
    - important technology theory
      - User experience design
- Data aggregation
    - assessment evidence database[@DOI:10.3390/educsci12100717]
    - challenges
      - limited clerks and technology specialists
- Data visualization
    - Learning analytics[@DOI:10.1080/02602938.2019.1694863]
    - dashboard[@DOI:10.3390/educsci12100717]
        - to gain holistic approach[@DOI:10.1080/0142159X.2021.1957088]
    - promote curriculum change[@DOI:10.1108/IJEM-10-2020-0494]
    - should be personalize
    - challenges
      - limited clerks and technology specialists
      - limited times for viewer
          - pressure of other duties
    - important technology theory
      - User experience design

## Technology as communication tools

### Why

- coaching
- co-creation
- coutenous quolity improvement

### Caution

- both may be the source of stress

### Type of communication

- Synchronous communication
- Asynchronous communication
  - email
  - chat

## Access control

- Authentication

## Why technology matter?

- To prevent bureaucracy, we need support systems to facilitate the entire process. Computer technology seems an obvious candidate for an important role as facilitator[@DOI:10.3109/0142159X.2012.652239]
    - reduce workload and provide intelligent solutions to some of the problems.
- removing unnecessary (administrative) burdens[@DOI:10.3390/educsci12100717]
- a significant investment in  technology (inadvertently facilitated by a pandemic) were key enablers of our PA approach[@DOI:10.3390/educsci12070487]

## ePortfolio in programmatic assessment

- de Jong, L. H., Bok, H. G. J., Kremer, W. D. J., & van der Vleuten, C. P. M. (2019). Programmatic assessment: Can we provide evidence for saturation of information? Medical Teacher, 41(6), 678–682. https://doi.org/10.1080/0142159X.2018.1555369


## Specialists and investigation

- involvement of learning  technology specialist[@DOI:10.3390/educsci12070487]
- Investiment in technology[@DOI:10.3390/educsci12070487]

## Articles

### issue of costs in programmatic assessment[@DOI:10.1007/s40037-016-0295-z]

- Technology may be used to capture feedback in a timeefficient way
- reflection apps and handheld IT devices


# References

Govaerts, M., Van der Vleuten, C., & Schut, S. (2022). Implementation of programmatic assessment: Challenges and lessons learned. Education in Science: The Bulletin of the Association for Science Education, 12(10), 717. https://doi.org/10.3390/educsci12100717

van der Vleuten, C. P. M., & Heeneman, S. (2016). On the issue of costs in programmatic assessment. Perspectives on Medical Education, 5(5), 303–307. https://doi.org/10.1007/s40037-016-0295-z

Ryan, A., & Judd, T. (2022). From Traditional to Programmatic Assessment in Three (Not So) Easy Steps. Education Sciences, 12(7), 487. https://doi.org/10.3390/educsci12070487

Wu, M., Brill, D. A., Prakash, S. M., Tan, J., Poptani, M., Wang, Y., & Haworth, I. S. (2021). Using technology to automate syllabus construction for programmatic, curricular, faculty and experiential assessment activities. International Journal of Educational Management, 36(1), 49–62. https://doi.org/10.1108/IJEM-10-2020-0494

van der Vleuten, C. P. M., Schuwirth, L. W. T., Driessen, E. W., Dijkstra, J., Tigelaar, D., Baartman, L. K. J., & van Tartwijk, J. (2012). A model for programmatic assessment fit for purpose. Medical Teacher, 34(3), 205–214. https://doi.org/10.3109/0142159X.2012.652239

Heeneman, S., de Jong, L. H., Dawson, L. J., Wilkinson, T. J., Ryan, A., Tait, G. R., Rice, N., Torre, D., Freeman, A., & van der Vleuten, C. P. M. (2021). Ottawa 2020 consensus statement for programmatic assessment - 1. Agreement on the principles. Medical Teacher, 43(10), 1139–1148. https://doi.org/10.1080/0142159X.2021.1957088

Archer, E., & Prinsloo, P. (2020). Speaking the unspoken in learning analytics: troubling the defaults. Assessment & Evaluation in Higher Education, 45(6), 888–900. https://doi.org/10.1080/02602938.2019.1694863