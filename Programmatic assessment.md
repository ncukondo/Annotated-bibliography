# Programmatic  assessment

## 12 principles of programmatic assessment

- Principle 1 every (part of an) assessment is but a data-point
- Principle 2 data-point is optimised for learning by giving meaningful feedback to the learner
- Principle 3 pass/fail decisions are not given on a single data-point
- Principle 4 there is a mix of methods of assessment
- Principle 5 the choice of method depends on the educational justification for using that method
- Principle 6 the distinction between summative and formative is replaced by a continuum of stakes
- Principle 7 decision-making on learner progress is proportionally related to the stake
- Principle 8 assessment information triangulation across data-points, towards an appropriate framework
- Principle 9: high-stakes decisions made in a credible and transparent manner, using a holistic approach
- Principle 10: intermediate review is made to discuss and decide with the learner on their progress
- Principle 11: earners have recurrent learning meetings with (faculty) mentors/coaches using a self- analysis of all assessment data
- Principle 12: programmatic assessment seeks to gradually increase the learner’s agency and accountability for their own learning through the learning being tailored to support individual learning priorities

Heeneman, S., de Jong, L. H., Dawson, L. J., Wilkinson, T. J., Ryan, A., Tait, G. R., Rice, N., Torre, D., Freeman, A., & van der Vleuten, C. P. M. (2021). Ottawa 2020 consensus statement for programmatic assessment - 1. Agreement on the principles. Medical Teacher, 43(10), 1139–1148. https://doi.org/10.1080/0142159X.2021.1957088

## Ottawa 2020 Implementation of programmatic assessment

### Implementation

1. Continuous and meaningful **feedback**
    - to promote a dialogue with the learner for the purpose of growth and development
    - assign coach or advisor
    - Most programmes used e-portofolio 
2. **Mixed methods** of assessment
    - across and within the context of a continuum of stakes
    - numerical and narrative data
3. Establishing equitable and credible **decision-making** processes
    - including principles of proportionality and triangulation.


### Enabler and Barriers

- Enabler
    - [ ] strong leadership support
        - a commitment to invest in software
(e-Portfolios) 
            - to support feedback delivery, learners’agency, and triangulation procedures for decision-making.
    - [ ] Ongoing faculty development
    - [ ] providing students with clear expectations about assessment
    - [ ] simultaneous curriculum renewal
    - [ ] organisational commitment to change
- Barriers
    - [ ] the need for a paradigm shift in the culture of assessment
        - embedded assessment and educational culture


Torre, D., Rice, N. E., Ryan, A., Bok, H., Dawson, L. J., Bierer, B., Wilkinson, T. J., Tait, G. R., Laughlin, T., Veerapen, K., Heeneman, S., Freeman, A., & van der Vleuten, C. (2021). Ottawa 2020 consensus statements for programmatic assessment - 2. Implementation and practice. Medical Teacher, 43(10), 1149–1160. https://doi.org/10.1080/0142159X.2021.1956681

## Feedback and Mentoring

- Feedback
    - aware about  the  activities  performed  well  and  areas  which  require  more  attention
    - how?
        - nonthreatening  atmosphere
        - nonjudgmental  manner
        - constructive
- Mentoring
    - feedback alone might not be sufficient to improve the learning of students
    - make students a self‑directed learner
        - accomplished  through  giving  an  effective  feedback  to  the  student  either  verbally  or  through a structured format
(Fischer et al., 2021 PMID:33776836)The Digital Stressors Scale: Development and Validation of a New Survey Instrument to Measure Digital Stress Perceptions in the Workplace Context. Frontiers in Psychology, 12, 607598. https://doi.org/10.3389/fpsyg.2021.607598 PMID:33776836

## International study on implementation


- knowledge brokers
    - drove and designed the implementation process acting by translating evidence int practice
- strategic opportunistic approach
    - agile approach
      - exploit opportunities
      - adapt context
      - manage and take advantage of the unexpected

Torre, D., Schuwirth, L., Van der Vleuten, C., & Heeneman, S. (2022). An international study on the implementation of programmatic assessment: Understanding challenges and exploring solutions. Medical Teacher, 44(8), 928–937. https://doi.org/10.1080/0142159X.2022.2083487

## Programmatic  assessment:  From  assessment of  learning  to  assessment  for  learning

This is the first article about programmatic assessment. Assessment of learning to assessment for leaning. It argues that there are limitations to measuring competency in a single assessment and advocates assessment as a program.

Schuwirth, L. W. T., & Van der Vleuten, C. P. M. (2011). Programmatic assessment: From assessment of learning to assessment for learning. Medical Teacher, 33(6), 478–485. https://doi.org/10.3109/0142159X.2011.565828

## Programmatic Assessment: The Secret Sauce of Effective CBME Implementation

This article advocates viewing CBME as a system and using programmatic assessment as part of that system.

Iobst, W. F., & Holmboe, E. S. (2020). Programmatic Assessment: The Secret Sauce of Effective CBME Implementation. Journal of Graduate Medical Education, 12(4), 518–521. https://doi.org/10.4300/JGME-D-20-00702.1

## A Core Components Framework for Evaluating  Implementation of Competency-Based Medical  Education Programs